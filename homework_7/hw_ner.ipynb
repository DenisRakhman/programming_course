{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Named entity recognition\n",
    "\n",
    "Для заданной тестовой выборки построить модель для обнаружения и классификации именованных сущностей (named entities). На базе корпуса CoNLL 2002.  \n",
    "\n",
    "Чем больше baseline'ов вы превзойдете, тем выше ваша оценка\n",
    "Метрика качества f1 (f1_macro) (чем выше, тем лучше)\n",
    " \n",
    "baseline 1: 0.0604      random labels  \n",
    "baseline 2: 0.3966      PoS features + logistic regression  \n",
    "baseline 3: 0.7559      word2vec cbow embedding + baseline 2 + svm    \n",
    "\n",
    "Пока мы рассмотрели только линейные модели - поэтому в примерах есть только они. Желательно при решении домашнего задания пользоваться линейными моделями. Таким образом, основные цели задания - feature engineering, hyperparam tuning & model selection.\n",
    "\n",
    "! Your results must be reproducible. Если ваша модель - стохастическая, то вы явно должны задавать все seed и random_state в параметрах моделей  \n",
    "! Вы должны использовать df_test только для измерения качества конечной обученной модели. \n",
    "\n",
    "bonus, think about:  \n",
    "1. how can you exploit that words belong to some sentence?\n",
    "2. why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  next-next-pos next-next-word next-pos      next-word  pos    prev-pos  \\\n",
       "0           NNS  demonstrators       IN             of  NNS  __START1__   \n",
       "1           VBP           have      NNS  demonstrators   IN         NNS   \n",
       "2           VBN        marched      VBP           have  NNS          IN   \n",
       "3            IN        through      VBN        marched  VBP         NNS   \n",
       "4           NNP         London       IN        through  VBN         VBP   \n",
       "\n",
       "  prev-prev-pos prev-prev-word      prev-word  sentence_idx           word tag  \n",
       "0    __START2__     __START2__     __START1__           1.0      Thousands   O  \n",
       "1    __START1__     __START1__      Thousands           1.0             of   O  \n",
       "2           NNS      Thousands             of           1.0  demonstrators   O  \n",
       "3            IN             of  demonstrators           1.0           have   O  \n",
       "4           NNS  demonstrators           have           1.0        marched   O  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner_short.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sentences\n",
    "df.sentence_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.852828\n",
       "B-geo    0.027604\n",
       "B-gpe    0.020935\n",
       "B-org    0.020247\n",
       "I-per    0.017795\n",
       "B-tim    0.016927\n",
       "B-per    0.015312\n",
       "I-org    0.013937\n",
       "I-geo    0.005383\n",
       "I-tim    0.004247\n",
       "B-art    0.001376\n",
       "I-gpe    0.000837\n",
       "I-art    0.000748\n",
       "B-eve    0.000628\n",
       "I-eve    0.000508\n",
       "B-nat    0.000449\n",
       "I-nat    0.000239\n",
       "Name: tag, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df.tag.value_counts(normalize=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence length\n",
    "tdf = df.set_index('sentence_idx')\n",
    "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
    "df = tdf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode categorial variables\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['pos'] = le.fit_transform(df.pos)\n",
    "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
    "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
    "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
    "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>London</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx  next-next-pos next-next-word  next-pos      next-word  pos  \\\n",
       "0           1.0             18  demonstrators         9             of   18   \n",
       "1           1.0             33           have        18  demonstrators    9   \n",
       "2           1.0             32        marched        33           have   18   \n",
       "3           1.0              9        through        32        marched   33   \n",
       "4           1.0             16         London         9        through   32   \n",
       "\n",
       "   prev-pos  prev-prev-pos prev-prev-word      prev-word           word tag  \\\n",
       "0        39             40     __START2__     __START1__      Thousands   O   \n",
       "1        18             39     __START1__      Thousands             of   O   \n",
       "2         9             18      Thousands             of  demonstrators   O   \n",
       "3        18              9             of  demonstrators           have   O   \n",
       "4        33             18  demonstrators           have        marched   O   \n",
       "\n",
       "   length  \n",
       "0      48  \n",
       "1      48  \n",
       "2      48  \n",
       "3      48  \n",
       "4      48  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 50155\n",
      "test 16719\n"
     ]
    }
   ],
   "source": [
    "# splitting\n",
    "y = LabelEncoder().fit_transform(df.tag)\n",
    "\n",
    "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
    "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
    "print('train', df_train.shape[0])\n",
    "print('test', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OHE = OneHotEncoder(n_values=15000, categorical_features='all')\n",
    "\n",
    "def OHEncode(df):\n",
    "    return OHE.fit_transform(np.array(df).reshape(-1, 1))\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    enc_pos = OHEncode(df_train['pos'])\n",
    "    enc_next_pos = OHEncode(df_train['next-pos'])\n",
    "    enc_next_next_pos = OHEncode(df_train['next-next-pos'])\n",
    "    enc_prev_pos = OHEncode(df_train['prev-pos'])\n",
    "    enc_prev_prev_pos = OHEncode(df_train['prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(analyzer='char', ngram_range=(2,5), max_features = 2000)\n",
    "\n",
    "enc_next_word = tfidf.fit_transform(df_train['next-word'])\n",
    "enc_next_next_word = tfidf.fit_transform(df_train['next-next-word'])\n",
    "enc_prev_word = tfidf.fit_transform(df_train['prev-word'])\n",
    "enc_prev_prev_word = tfidf.fit_transform(df_train['prev-prev-word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "X_train = sp.hstack((enc_pos, enc_next_pos, enc_next_next_pos,\n",
    "                     enc_prev_pos, enc_prev_prev_pos, \n",
    "                    enc_next_word, enc_next_next_word,\n",
    "                     enc_prev_word, enc_prev_prev_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    enc_pos_test = OHEncode(df_test['pos'])\n",
    "    enc_next_pos_test = OHEncode(df_test['next-pos'])\n",
    "    enc_next_next_pos_test = OHEncode(df_test['next-next-pos'])\n",
    "    enc_prev_pos_test = OHEncode(df_test['prev-pos'])\n",
    "    enc_prev_prev_pos_test = OHEncode(df_test['prev-prev-pos'])\n",
    "\n",
    "    enc_next_word_test = tfidf.transform(df_test['next-word'])\n",
    "    enc_next_next_word_test = tfidf.transform(df_test['next-next-word'])\n",
    "    enc_prev_word_test = tfidf.transform(df_test['prev-word'])\n",
    "    enc_prev_prev_word_test = tfidf.transform(df_test['prev-prev-word'])\n",
    "    \n",
    "X_test = sp.hstack((enc_pos_test, enc_next_pos_test, enc_next_next_pos_test,\n",
    "                     enc_prev_pos_test, enc_prev_prev_pos_test, \n",
    "                    enc_next_word_test, enc_next_next_word_test,\n",
    "                     enc_prev_word_test, enc_prev_prev_word_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] fit_intercept=True, loss=hinge, shuffle=True ....................\n",
      "[CV] ..... fit_intercept=True, loss=hinge, shuffle=True, total=   0.8s\n",
      "[CV] fit_intercept=True, loss=hinge, shuffle=True ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... fit_intercept=True, loss=hinge, shuffle=True, total=   1.8s\n",
      "[CV] fit_intercept=True, loss=hinge, shuffle=True ....................\n",
      "[CV] ..... fit_intercept=True, loss=hinge, shuffle=True, total=   1.3s\n",
      "[CV] fit_intercept=True, loss=hinge, shuffle=False ...................\n",
      "[CV] .... fit_intercept=True, loss=hinge, shuffle=False, total=   1.0s\n",
      "[CV] fit_intercept=True, loss=hinge, shuffle=False ...................\n",
      "[CV] .... fit_intercept=True, loss=hinge, shuffle=False, total=   0.4s\n",
      "[CV] fit_intercept=True, loss=hinge, shuffle=False ...................\n",
      "[CV] .... fit_intercept=True, loss=hinge, shuffle=False, total=   0.5s\n",
      "[CV] fit_intercept=True, loss=log, shuffle=True ......................\n",
      "[CV] ....... fit_intercept=True, loss=log, shuffle=True, total=   3.1s\n",
      "[CV] fit_intercept=True, loss=log, shuffle=True ......................\n",
      "[CV] ....... fit_intercept=True, loss=log, shuffle=True, total=   2.6s\n",
      "[CV] fit_intercept=True, loss=log, shuffle=True ......................\n",
      "[CV] ....... fit_intercept=True, loss=log, shuffle=True, total=   2.3s\n",
      "[CV] fit_intercept=True, loss=log, shuffle=False .....................\n",
      "[CV] ...... fit_intercept=True, loss=log, shuffle=False, total=   2.5s\n",
      "[CV] fit_intercept=True, loss=log, shuffle=False .....................\n",
      "[CV] ...... fit_intercept=True, loss=log, shuffle=False, total=   1.3s\n",
      "[CV] fit_intercept=True, loss=log, shuffle=False .....................\n",
      "[CV] ...... fit_intercept=True, loss=log, shuffle=False, total=   2.4s\n",
      "[CV] fit_intercept=True, loss=modified_huber, shuffle=True ...........\n",
      "[CV]  fit_intercept=True, loss=modified_huber, shuffle=True, total=   2.3s\n",
      "[CV] fit_intercept=True, loss=modified_huber, shuffle=True ...........\n",
      "[CV]  fit_intercept=True, loss=modified_huber, shuffle=True, total=   2.0s\n",
      "[CV] fit_intercept=True, loss=modified_huber, shuffle=True ...........\n",
      "[CV]  fit_intercept=True, loss=modified_huber, shuffle=True, total=   1.4s\n",
      "[CV] fit_intercept=True, loss=modified_huber, shuffle=False ..........\n",
      "[CV]  fit_intercept=True, loss=modified_huber, shuffle=False, total=   0.5s\n",
      "[CV] fit_intercept=True, loss=modified_huber, shuffle=False ..........\n",
      "[CV]  fit_intercept=True, loss=modified_huber, shuffle=False, total=   1.1s\n",
      "[CV] fit_intercept=True, loss=modified_huber, shuffle=False ..........\n",
      "[CV]  fit_intercept=True, loss=modified_huber, shuffle=False, total=   1.1s\n",
      "[CV] fit_intercept=True, loss=squared_hinge, shuffle=True ............\n",
      "[CV]  fit_intercept=True, loss=squared_hinge, shuffle=True, total=   2.1s\n",
      "[CV] fit_intercept=True, loss=squared_hinge, shuffle=True ............\n",
      "[CV]  fit_intercept=True, loss=squared_hinge, shuffle=True, total=   2.2s\n",
      "[CV] fit_intercept=True, loss=squared_hinge, shuffle=True ............\n",
      "[CV]  fit_intercept=True, loss=squared_hinge, shuffle=True, total=   2.2s\n",
      "[CV] fit_intercept=True, loss=squared_hinge, shuffle=False ...........\n",
      "[CV]  fit_intercept=True, loss=squared_hinge, shuffle=False, total=   1.2s\n",
      "[CV] fit_intercept=True, loss=squared_hinge, shuffle=False ...........\n",
      "[CV]  fit_intercept=True, loss=squared_hinge, shuffle=False, total=   1.2s\n",
      "[CV] fit_intercept=True, loss=squared_hinge, shuffle=False ...........\n",
      "[CV]  fit_intercept=True, loss=squared_hinge, shuffle=False, total=   1.2s\n",
      "[CV] fit_intercept=True, loss=perceptron, shuffle=True ...............\n",
      "[CV]  fit_intercept=True, loss=perceptron, shuffle=True, total=   2.1s\n",
      "[CV] fit_intercept=True, loss=perceptron, shuffle=True ...............\n",
      "[CV]  fit_intercept=True, loss=perceptron, shuffle=True, total=   2.0s\n",
      "[CV] fit_intercept=True, loss=perceptron, shuffle=True ...............\n",
      "[CV]  fit_intercept=True, loss=perceptron, shuffle=True, total=   1.4s\n",
      "[CV] fit_intercept=True, loss=perceptron, shuffle=False ..............\n",
      "[CV]  fit_intercept=True, loss=perceptron, shuffle=False, total=   0.7s\n",
      "[CV] fit_intercept=True, loss=perceptron, shuffle=False ..............\n",
      "[CV]  fit_intercept=True, loss=perceptron, shuffle=False, total=   1.1s\n",
      "[CV] fit_intercept=True, loss=perceptron, shuffle=False ..............\n",
      "[CV]  fit_intercept=True, loss=perceptron, shuffle=False, total=   1.1s\n",
      "[CV] fit_intercept=False, loss=hinge, shuffle=True ...................\n",
      "[CV] .... fit_intercept=False, loss=hinge, shuffle=True, total=   2.4s\n",
      "[CV] fit_intercept=False, loss=hinge, shuffle=True ...................\n",
      "[CV] .... fit_intercept=False, loss=hinge, shuffle=True, total=   2.2s\n",
      "[CV] fit_intercept=False, loss=hinge, shuffle=True ...................\n",
      "[CV] .... fit_intercept=False, loss=hinge, shuffle=True, total=   2.0s\n",
      "[CV] fit_intercept=False, loss=hinge, shuffle=False ..................\n",
      "[CV] ... fit_intercept=False, loss=hinge, shuffle=False, total=   1.1s\n",
      "[CV] fit_intercept=False, loss=hinge, shuffle=False ..................\n",
      "[CV] ... fit_intercept=False, loss=hinge, shuffle=False, total=   1.1s\n",
      "[CV] fit_intercept=False, loss=hinge, shuffle=False ..................\n",
      "[CV] ... fit_intercept=False, loss=hinge, shuffle=False, total=   1.0s\n",
      "[CV] fit_intercept=False, loss=log, shuffle=True .....................\n",
      "[CV] ...... fit_intercept=False, loss=log, shuffle=True, total=   3.9s\n",
      "[CV] fit_intercept=False, loss=log, shuffle=True .....................\n",
      "[CV] ...... fit_intercept=False, loss=log, shuffle=True, total=   3.9s\n",
      "[CV] fit_intercept=False, loss=log, shuffle=True .....................\n",
      "[CV] ...... fit_intercept=False, loss=log, shuffle=True, total=   4.1s\n",
      "[CV] fit_intercept=False, loss=log, shuffle=False ....................\n",
      "[CV] ..... fit_intercept=False, loss=log, shuffle=False, total=   2.8s\n",
      "[CV] fit_intercept=False, loss=log, shuffle=False ....................\n",
      "[CV] ..... fit_intercept=False, loss=log, shuffle=False, total=   2.8s\n",
      "[CV] fit_intercept=False, loss=log, shuffle=False ....................\n",
      "[CV] ..... fit_intercept=False, loss=log, shuffle=False, total=   2.7s\n",
      "[CV] fit_intercept=False, loss=modified_huber, shuffle=True ..........\n",
      "[CV]  fit_intercept=False, loss=modified_huber, shuffle=True, total=   2.1s\n",
      "[CV] fit_intercept=False, loss=modified_huber, shuffle=True ..........\n",
      "[CV]  fit_intercept=False, loss=modified_huber, shuffle=True, total=   2.1s\n",
      "[CV] fit_intercept=False, loss=modified_huber, shuffle=True ..........\n",
      "[CV]  fit_intercept=False, loss=modified_huber, shuffle=True, total=   2.0s\n",
      "[CV] fit_intercept=False, loss=modified_huber, shuffle=False .........\n",
      "[CV]  fit_intercept=False, loss=modified_huber, shuffle=False, total=   1.0s\n",
      "[CV] fit_intercept=False, loss=modified_huber, shuffle=False .........\n",
      "[CV]  fit_intercept=False, loss=modified_huber, shuffle=False, total=   0.5s\n",
      "[CV] fit_intercept=False, loss=modified_huber, shuffle=False .........\n",
      "[CV]  fit_intercept=False, loss=modified_huber, shuffle=False, total=   0.7s\n",
      "[CV] fit_intercept=False, loss=squared_hinge, shuffle=True ...........\n",
      "[CV]  fit_intercept=False, loss=squared_hinge, shuffle=True, total=   2.0s\n",
      "[CV] fit_intercept=False, loss=squared_hinge, shuffle=True ...........\n",
      "[CV]  fit_intercept=False, loss=squared_hinge, shuffle=True, total=   2.0s\n",
      "[CV] fit_intercept=False, loss=squared_hinge, shuffle=True ...........\n",
      "[CV]  fit_intercept=False, loss=squared_hinge, shuffle=True, total=   1.0s\n",
      "[CV] fit_intercept=False, loss=squared_hinge, shuffle=False ..........\n",
      "[CV]  fit_intercept=False, loss=squared_hinge, shuffle=False, total=   1.0s\n",
      "[CV] fit_intercept=False, loss=squared_hinge, shuffle=False ..........\n",
      "[CV]  fit_intercept=False, loss=squared_hinge, shuffle=False, total=   1.0s\n",
      "[CV] fit_intercept=False, loss=squared_hinge, shuffle=False ..........\n",
      "[CV]  fit_intercept=False, loss=squared_hinge, shuffle=False, total=   1.1s\n",
      "[CV] fit_intercept=False, loss=perceptron, shuffle=True ..............\n",
      "[CV]  fit_intercept=False, loss=perceptron, shuffle=True, total=   2.1s\n",
      "[CV] fit_intercept=False, loss=perceptron, shuffle=True ..............\n",
      "[CV]  fit_intercept=False, loss=perceptron, shuffle=True, total=   2.0s\n",
      "[CV] fit_intercept=False, loss=perceptron, shuffle=True ..............\n",
      "[CV]  fit_intercept=False, loss=perceptron, shuffle=True, total=   1.4s\n",
      "[CV] fit_intercept=False, loss=perceptron, shuffle=False .............\n",
      "[CV]  fit_intercept=False, loss=perceptron, shuffle=False, total=   0.8s\n",
      "[CV] fit_intercept=False, loss=perceptron, shuffle=False .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  fit_intercept=False, loss=perceptron, shuffle=False, total=   1.0s\n",
      "[CV] fit_intercept=False, loss=perceptron, shuffle=False .............\n",
      "[CV]  fit_intercept=False, loss=perceptron, shuffle=False, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clf = GridSearchCV(SGDClassifier(), \n",
    "                       {'loss': ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'),\n",
    "                       'fit_intercept' : (True, False), \n",
    "                       'shuffle' : (True, False)}, \n",
    "                        verbose=2)\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': False, 'loss': 'modified_huber', 'shuffle': True}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.898040560492\n",
      "test 0.353134454584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model = SGDClassifier(fit_intercept=False,\n",
    "                         loss='modified_huber',\n",
    "                         penalty='l2',\n",
    "                         shuffle=True,\n",
    "                         random_state=SEED)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
    "    print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
